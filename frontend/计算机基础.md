# 计算机基础

## 操作系统

### [进程和线程](https://juejin.cn/post/6844903801321685000)

进程 = 线程+内存+文件/网络句柄

线程 = 栈+PC+TLS

1. 进程是资源分配的最小单位，线程是程序执行调度的最小单位。
2. 进程要分配一大部分的内存，而线程只需要分配一部分栈就可以了.
3. 一个程序至少有一个进程，一个进程至少有一个线程.
4. 一个线程可以创建和撤销另一个线程，同一个进程中的多个线程之间可以并发执行.

线程才是我们操作系统所真正去运行的，而进程则是像容器一样，他把需要的一些东西放在一起，而把不需要的东西做了一层隔离

缓冲区溢出：一个漏洞，可以被黑客利用执行脚本

PC，Program Counter 程序计数器，就是指向当前的指令，而这个指令是放在内存中。 每个线程都有一串自己的指针，去指向自己当前所在内存的指针。

TLS，thread local storage，线程本地存储

### [进程通信](https://www.jianshu.com/p/c1015f5ffa74)

Inter Process Communication

每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程 1 把数据从用户空间拷到`内核缓冲区`，进程 2 再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信（IPC，Inter Process Communication）

进程间通信的 7 种方式

- 管道/匿名管道(pipe)
- 有名管道(FIFO)
- 信号(Signal)
- 消息队列(Message Queue)
- 共享内存(share memory)
- 信号量(semaphore)
- 套接字(socket)

### [进程调度策略](https://blog.csdn.net/qq_35642036/article/details/82809812)

- 先来先服务调度算法
- 短作业(进程)优先调度算法
  对短作业或短进程优先调度的算法
- 高优先权优先调度算法
  为了照顾紧迫型作业，使之在进入系统后便获得优先处理
- 高响应比优先调度算法
- 时间片轮转法
- 多级反馈队列调度算法

### [死锁](https://www.jianshu.com/p/44125bb12ebf)

死锁

当线程 A 持有独占锁 a，并尝试去获取独占锁 b 的同时，线程 B 持有独占锁 b，并尝试获取独占锁 a 的情况下，就会发生 AB 两个线程由于互相持有对方需要的锁，而发生的阻塞现象，我们称为死锁。

造成死锁必须达成的 4 个条件（原因）：

- 互斥条件：一个资源每次只能被一个线程使用。
- 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
- 不剥夺条件：线程已获得的资源，在未使用完之前，不能强行剥夺。
- 循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。

如何避免？

在并发程序中，避免了逻辑中出现数个线程互相持有对方线程所需要的独占锁的的情况，就可以避免死锁。

### [IO 多路复用](https://imageslr.github.io/2020/02/27/select-poll-epoll.html)

阻塞 I/O，是指进程发起调用后，会被挂起（阻塞），直到收到数据再返回。如果调用一直不返回，进程就会一直被挂起。因此，当使用阻塞 I/O 时，需要使用多线程来处理多个文件描述符。

多线程切换有一定的开销，因此引入非阻塞 I/O。非阻塞 I/O 不会将进程挂起，调用时会立即返回成功或错误，因此可以在一个线程里轮询多个文件描述符是否就绪。

但是非阻塞 I/O 的缺点是：每次发起系统调用，只能检查一个文件描述符是否就绪。当文件描述符很多时，系统调用的成本很高。

因此引入了 I/O 多路复用，可以通过一次系统调用，检查多个文件描述符的状态。这是 I/O 多路复用的主要优点，相比于非阻塞 I/O，在文件描述符较多的场景下，避免了频繁的用户态和内核态的切换，减少了系统调用的开销。

I/O 多路复用相当于将「遍历所有文件描述符、通过非阻塞 I/O 查看其是否就绪」的过程从用户线程移到了内核中，由内核来负责轮询。

进程可以通过 select、poll、epoll 发起 I/O 多路复用的系统调用，这些系统调用都是同步阻塞的：如果传入的多个文件描述符中，有描述符就绪，则返回就绪的描述符；否则如果所有文件描述符都未就绪，就阻塞调用进程，直到某个描述符就绪，或者阻塞时长超过设置的 timeout 后，再返回。使用非阻塞 I/O 检查每个描述符的就绪状态。

如果 timeout 参数设为 NULL，会无限阻塞直到某个描述符就绪；如果 timeout 参数设为 0，会立即返回，不阻塞。

I/O 多路复用引入了一些额外的操作和开销，性能更差。但是好处是用户可以在一个线程内同时处理多个 I/O 请求。如果不采用 I/O 多路复用，则必须通过多线程的方式，每个线程处理一个 I/O 请求。后者线程切换也是有一定的开销的。这部分内容可以查看最下文 Redis 的线程模型。

## 网络

> [面试官（9）：可能是全网最全的 http 面试答案](https://juejin.cn/post/6844903865410650126)

### [七层网络模型](https://zhuanlan.zhihu.com/p/32059190)

OSI 七层网络模型

- yy 应用层——为应用程序提供网络服务
- bs 表示层——数据格式化，加解密
- hh 会话层——建立、维护、管理会话
- cs 传输层——建立、维护、管理端到端连接
- wl 网络层——IP 寻址和路由选择
- sjll 数据链路层——控制网络层与物理层之间通信
- wl 物理层——比特流传输，传输 byte 流，物理连接

TCP/IP 四层模型

- yy 应用层
- cs 传输层
- wl 网络层
- sjll 数据链路层

![数据链路层数据包（以太网数据包）格式](https://pic2.zhimg.com/80/v2-3c8ab7e3f330238821adedea31b9c321_1440w.jpg)

![数据包在传送时的封装和解封装](https://pic3.zhimg.com/80/v2-80430dbb37a1e42315a77e30448b34b2_1440w.jpg)

### HTTP 常用的状态码及使用场景

- 1xx：表示目前是协议的中间状态，还需要后续请求
- 2xx：表示请求成功
- 3xx：表示重定向状态，需要重新请求
- 4xx：表示请求报文错误
- 5xx：服务器端错误

常用状态码

- 101 切换请求协议，从 HTTP 切换到 WebSocket
- 200 请求成功，有响应体
- 301 永久重定向：会缓存
- 302 临时重定向：不会缓存
- 304 协商缓存命中
- 400 请求错误
- 401
- 403 服务器禁止访问
- 404 资源未找到
- 500 服务器端错误
- 503 服务器繁忙

### 301/302 重定向

302 表示临时重定向，这个资源只是暂时不能被访问了，但是之后过一段时间还是可以继续访问，一般是访问某个网站的资源需要权限时，会需要用户去登录，跳转到登录页面之后登录之后，还可以继续访问。

301 类似，都会跳转到一个新的网站，但是 301 代表访问的地址的资源被永久移除了，以后都不应该访问这个地址，搜索引擎抓取的时候也会用新的地址替换这个老的。可以在返回的响应的 location 首部去获取到返回的地址。

301 的场景如下：

- 比如从 http://baidu.com，跳转到 https://baidu.com
- 域名换了

### HTTP 常用的请求方式，区别和用途？

http/1.1 规定如下请求方法：

- GET：通用获取数据
- POST：提交数据
- PUT：修改数据
- DELETE：删除数据
- HEAD：获取资源的元信息
- CONNECT：建立连接隧道，用于代理服务器
- OPTIONS：列出可对资源实行的请求方法，常用于跨域
- TRACE：追踪请求-响应的传输路径

### http 知道嘛？哪一层的协议？（应用层）

- 灵活可扩展，除了规定空格分隔单词，换行分隔字段以外，其他都没有限制，不仅仅可以传输文本，还可以传输图片、视频等任意资源
- 可靠传输，基于 TCP/IP 所以继承了这一特性
- 请求-应答，有来有回
- 无状态，每次 HTTP 请求都是独立的，无关的、默认不需要保存上下文信息

缺点：

- 明文传输不安全
- 复用一个 TCP 链接，会发生对头拥塞
- 无状态在长连接场景中，需要保存大量上下文，以避免传输大量重复的信息

### [http](https://coolshell.cn/articles/19840.html)

HTTP (Hypertext transfer protocol) 超文本传输协议

1991 年发布了 HTTP 0.9 版，在 1996 年发布 1.0 版，1997 年是 1.1 版，1.1 版也是到今天为止传输最广泛的版本

2015 年发布了 2.0 版，其极大的优化了 HTTP/1.1 的性能和安全性，而 2018 年发布的 3.0 版，继续优化 HTTP/2，激进地使用 UDP 取代 TCP 协议

HTTP/1.0

- 在请求中加入了 HTTP 版本号，如：GET /coolshell/index.html HTTP/1.0
- HTTP 开始有 header 了，不管是 request 还是 response 都有 header 了。
- 增加了 HTTP Status Code 标识相关的状态码。
- 还有 Content-Type 可以传输其它的文件了。

- 一个协议有没有版本管理，是一个工程化的象征。
- header 是协议可以说是把元数据和业务数据解耦，也可以说是控制逻辑和业务逻辑的分离。
- Status Code 的出现可以让请求双方以及第三方的监控或管理程序有了统一的认识。最关键是还是控制错误和业务错误的分离。

问题

HTTP1.0 性能上有一个很大的问题，那就是每请求一个资源都要新建一个 TCP 链接，而且是串行请求，所以，就算网络变快了，打开网页的速度也还是很慢。所以，HTTP 1.0 应该是一个必需要淘汰的协议了。

HTTP/1.1

- HTTP/1.1 主要解决了 HTTP 1.0 的网络性能的问题
- 可以设置 keepalive 来让 HTTP 重用 TCP 链接，重用 TCP 链接可以省了每次请求都要在广域网上进行的 TCP 的三次握手的巨大开销。这是所谓的“HTTP 长链接” 或是 “请求响应式的 HTTP 持久链接”。英文叫 HTTP Persistent connection.
- 然后支持 pipeline 网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。（注：非幂等的 POST 方法或是有依赖的请求是不能被 pipeline 化的）
- 支持 Chunked Responses ，也就是说，在 Response 的时候，不必说明 Content-Length 这样，客户端就不能断连接，直到收到服务端的 EOF 标识。这种技术又叫 “服务端 Push 模型”，或是 “服务端 Push 式的 HTTP 持久链接”
- 还增加了 cache control 机制。
- 协议头注增加了 Language, Encoding, Type 等等头，让客户端可以跟服务器端进行更多的协商。
- 还正式加入了一个很重要的头—— HOST 这样的话，服务器就知道你要请求哪个网站了。因为可以有多个域名解析到同一个 IP 上，要区分用户是请求的哪个域名，就需要在 HTTP 的协议中加入域名的信息，而不是被 DNS 转换过的 IP 信息。
- 正式加入了 OPTIONS 方法，其主要用于 CORS – Cross Origin Resource Sharing 应用。

HTTP/1.1 应该分成两个时代，一个是 2014 年前，一个是 2014 年后，因为 2014 年 HTTP/1.1 有了一组 RFC（7230 /7231/7232/7233/7234/7235），这组 RFC 又叫“HTTP/2 预览版”。

其中影响 HTTP 发展的是两个大的需求：

- 一个需要是加大了 HTTP 的安全性，这样就可以让 HTTP 应用得广泛，比如，使用 TLS 协议。
- 另一个是让 HTTP 可以支持更多的应用，在 HTTP/1.1 下，HTTP 已经支持四种网络协议：
  - 传统的短链接。
  - 可重用 TCP 的的长链接模型。
  - 服务端 push 的模型。
  - WebSocket 模型。

### [https](https://zhuanlan.zhihu.com/p/26682342)

> HTTPS 是在 HTTP 和 TCP 之间建立了一个安全层，HTTP 与 TCP 通信的时候，必须先经过一个安全层，`对数据包进行加密`，然后将加密后的数据包传送给 TCP，相应的 TCP 必须`将数据包解密`，才能传给上面的 HTTP。
>
> HTTP -> 加密 -> TCP -> TCP -> 解密 -> HTTP
>
> 浏览器传输一个 `client_random` 和`加密方法列表`，服务器收到后，传给浏览器一个 `server_random`、`加密方法列表`和`数字证书（包含了公钥）`，然后浏览器对数字证书进行合法验证，如果验证通过，则生成一个 `pre_random`，然后用公钥加密传给服务器，服务器用 `client_random`、`server_random` 和 `pre_random`，使用公钥加密生成 `secret`，然后之后的传输使用这个 secret 作为秘钥来进行数据的加解密。

- 数据加密 传输内容进行混淆
- 身份验证 通信双方验证对方的身份真实性
- 数据完整性保护 检测传输的内容是否被篡改或伪造

HTTPS 采用共享密钥加密和公开密钥加密混合的加密方式，在交换密钥对环节使用公开密钥加密方式（防止被监听泄漏密钥）加密共享的密钥，在随后的通信过程中使用共享密钥的方式使用共享的密钥进行加解密。

#### 数字证书

数字证书认证机构（Certificate Authority CA）是客户端和服务器双方都可信赖的第三方机构。

数字签名是只有信息发送者才能产生的别人无法伪造的一段文本，这段文本是对信息发送者发送信息真实性的一个有效证明，具有不可抵赖性。

### [http2.0](https://juejin.cn/post/6844903984524705800)

- 二进制分帧协议
- 多路复用
- 头部压缩
- 服务端推送
- 流控

http2.0 之所以能够突破 http1.X 标准的性能限制，改进传输性能，实现低延迟和高吞吐量，就是因为其新增了二进制分帧层。

在 http1.1 中，浏览器客户端在同一时间，针对同一域名下的请求有一定数量的限制，超过限制数目的请求会被阻塞。这也是为何一些站点会有多个静态资源 CDN 域名的原因之一。

http2.0 中的多路复用优化了这一性能。多路复用允许同时通过单一的 http/2 连接发起多重的请求-响应消息。有了新的分帧机制后，http/2 不再依赖多个 TCP 连接去实现多流并行了。每个数据流都拆分成很多互不依赖的帧，而这些帧可以交错（乱序发送），还可以分优先级，最后再在另一端把它们重新组合起来。

http 2.0 连接都是持久化的，而且客户端与服务器之间也只需要一个连接（每个域名一个连接）即可。http2 连接可以承载数十或数百个流的复用，多路复用意味着来自很多流的数据包能够混合在一起通过同样连接传输。当到达终点时，再根据不同帧首部的流标识符重新连接将不同的数据流进行组装。

http1.x 的头带有大量信息，而且每次都要重复发送。http/2 使用 encoder 来减少需要传输的 header 大小，通讯双方各自缓存一份头部字段表，既避免了重复 header 的传输，又减小了需要传输的大小。

如果首部发生了变化，则只需将变化的部分加入到 header 帧中，改变的部分会加入到头部字段表中，首部表在 http 2.0 的连接存续期内始终存在，由客户端和服务器共同渐进地更新。

http/2 的 HPACK 算法使用一份索引表来定义常用的 http Header，把常用的 http Header 存放在表里，请求的时候便只需要发送在表里的索引位置即可。

把 http 消息分为很多独立帧之后，就可以通过优化这些帧的交错和传输顺序进一步优化性能。每个流都可以带有一个 31 比特的优先值：0 表示最高优先级；2 的 31 次方-1 表示最低优先级。
服务器可以根据流的优先级，控制资源分配（CPU、内存、带宽），而在响应数据准备好之后，优先将最高优先级的帧发送给客户端。

服务器可以对一个客户端请求发送多个响应，服务器向客户端推送资源无需客户端明确地请求。并且，服务端推送能把客户端所需要的资源伴随着 index.html 一起发送到客户端，省去了客户端重复请求的步骤。

那么肯定要问 HTTP2.0 虽然性能已经不错了，还有什么不足吗？

- 建立连接时间长(本质上是 TCP 的问题，三次握手四次挥手)
- 队头阻塞问题，拥塞控制
- 移动互联网领域表现不佳(弱网环境)

### [http3.0](https://blog.csdn.net/wolfGuiDao/article/details/108729560)

我们单纯地看看 TCP 协议的不足和 UDP 的一些优点：

- 基于 TCP 开发的设备和协议非常多，兼容困难
- TCP 协议栈是 Linux 内部的重要部分，修改和升级成本很大
- UDP 本身是无连接的、没有建链和拆链成本
- UDP 的数据包无队头阻塞问题
- UDP 改造成本小

谷歌决定在 UDP 基础上改造一个具备 TCP 协议优点的新协议，这个新协议就是 QUIC 协议，Quick UDP Internet Connections

---

QUIC 协议存在的意义在于解决 TCP 协议的一些无法解决的痛点：

- 多次握手：TCP 协议需要三次握手建立连接，而如果需要 TLS 证书的交换，那么则需要更多次的握手才能建立可靠连接，这在如今长肥网络的趋势下是一个巨大的痛点
- 队头阻塞：TCP 协议下，如果出现丢包，则一条连接将一直被阻塞等待该包的重传，即使后来的数据包可以被缓存，但也无法被递交给应用层去处理。
- 无法判断一个 ACK 是重传包的 ACK 还是原本包的 ACK：比如 一个包 seq=1, 超时重传的包同样是 seq=1，这样在收到一个 ack=1 之后，我们无法判断这个 ack 是对之前的包的 ack 还是对重传包的 ack，这会导致我们对 RTT 的估计出现误差，无法提供更准确的拥塞控制
- 无法进行连接迁移：一条连接由一个四元组标识，在当今移动互联网的时代，如果一台手机从一个 wifi 环境切换到另一个 wifi 环境，ip 发生变化，那么连接必须重新建立，inflight 的包全部丢失。

现在我们给出一个 QUIC 协议的 Overview

- 更好的连接建立方式
- 更好的拥塞控制
- 没有队头阻塞的多路复用
- 前向纠错
- 连接迁移

### [websocket](https://blog.csdn.net/LL845876425/article/details/106393358)

为什么会出现？

HTTP 协议有一个的缺陷为：通信只能由客户端发起。这种单向请求的特点，注定了如果服务器有连续的状态变化，客户端要获知就非常麻烦。

一个方案是使用轮询：每隔一段时候，就发出一个询问，了解服务器有没有新的信息。最典型的场景就是聊天室。轮询的效率低，非常浪费资源（因为必须不停连接，或者 HTTP 连接始终打开）。WebSocket 就是这样发明的。

Webscoket 是 Web 浏览器和服务器之间的一种全双工通信协议，一旦 Web 客户端与服务器建立起连接，之后的全部数据通信都通过这个连接进行。通信过程中，可互相发送 JSON、XML、HTML 或图片等任意格式的数据。

WS（WebSocket）与 HTTP 协议相比，

相同点主要有：

- 都是基于 TCP 的应用层协议；
- 都使用 Request/Response 模型进行连接的建立；
- 在连接的建立过程中对错误的处理方式相同，在这个阶段 WS 可能返回和 HTTP 相同的返回码；
- 都可以在网络中传输数据。

不同之处在于：

- WS 使用 HTTP 来建立连接，但是定义了一系列新的 header 域，这些域在 HTTP 中并不会使用；
- WS 的连接不能通过中间人来转发，它必须是一个直接连接；
- WS 连接建立之后，通信双方都可以在任何时刻向另一方发送数据；全双工？
- WS 连接建立之后，数据的传输使用帧来传递，不再需要 Request 消息；
- WS 的数据帧有序。

### [tcp](https://coolshell.cn/articles/11564.html)

> https://zhuanlan.zhihu.com/p/47861654

1. 面向连接
2. 可靠传输
3. 面向字节流
4. 提供拥塞控制
5. 仅支持单播传输
6. 提供全双工通信

|          | TCP                                         | UDP                                    |
| -------- | ------------------------------------------- | -------------------------------------- |
| 是否连接 | 无连接                                      | 面向连接                               |
| 是否可靠 | 不可靠传输，不使用流量控制和拥塞控制        | 可靠传输，使用流量控制和拥塞控制       |
| 连接个数 | 支持一对一，一对多，多对一和多对多交互通信  | 只能是一对一通信                       |
| 传输方式 | 面向报文                                    | 面向字节流                             |
| 首部开销 | 首部开销小，仅 8 字节                       | 首部最小 20 字节，最大 60 字节         |
| 使用场景 | 适用于实时应用（IP 电话、视频会议、直播等） | 适用于要求可靠传输的应用，例如文件传输 |

### [udp](https://zhuanlan.zhihu.com/p/337678680)

1. 面向无连接
2. 不可靠传输，丢包不重发
3. 面向报文
4. 不提供复杂的控制机制，不保证顺序，不控制流量
5. 单播、多播、广播皆可
6. 资源开销小，传输数据报文时很高效，适合传输音视频

### TCP 协议怎么保证可靠的，UDP 为什么不可靠？

- TCP 是面向连接的、可靠的、传输层通信协议
- UDP 是无连接的传输层通信协议，继承 IP 特性,基于数据报

#### 为什么 TCP 可靠？

TCP 的可靠性体现在有状态和控制

- 会精准记录那些数据发送了，那些数据被对方接收了，那些没有被接收，而且保证数据包按序到达，不允许半点差错，这就是有状态
- 当意识到丢包了或者网络环境不佳，TCP 会根据具体情况调整自己的行为，控制自己的发送速度或者重发，这是可控制的
- 反之 UDP 就是无状态的和不可控制的

### 三次握手和四次挥手

浅显的说，是为了确认对方的发送和接收能力。

- SYN（synchronize）
- ACK（acknowledgement）

#### 三次握手，建立连接

> TCP 三次握手为了保证数据能到达目标，TCP 采用三次握手策略。
>
> 1. 发送端首先发送一个带 SYN（synchronize）标志的数据包给接收方【第一次的 seq 序列号是随机产生的，这样是为了网络安全，如果不是随机产生初始序列号，黑客将会以很容易的方式获取到你与其他主机之间的初始化序列号，并且伪造序列号进行攻击】
>
> 2. 接收端收到后，回传一个带有 SYN/ACK（acknowledgement）标志的数据包以示传达确认信息【SYN 是为了告诉发送端，发送方到接收方的通道没问题？ACK 用来验证接收方到发送方的通道没问题？是不是说反了，ACK 确认，SYN 验证】
>
> 3. 最后，发送端再回传一个带 ACK 标志的数据包，代表握手结束。若在握手某个过程中某个阶段莫名中断，TCP 协议会再次以相同的顺序发送相同的数据包

- 一开始双方处于 CLOSED 状态，然后服务端开始监听某个端口进入 LISTEN 状态
- 然后客户端主动发起连接，发送 SYN 报文，然后自己变为 SYN-SEND，seq = x
- 服务端收到之后，返回 SYN seq = y 和 ACK ack = x + 1（对于客户端发来的 SYN），自己变成 SYN-RCVD
- 之后客户端再次发送 ACK seq = x + 1, ack = y + 1 给服务端，自己变成 ESTABLISHED 状态，服务端收到 ACK 报文，也进入 ESTABLISHED

> SYN 需要对端确认，所以 ACK 的序列化要加一，凡是需要对端确认的，一定要消耗 TCP 报文的序列化

![三次握手](https://img-blog.csdn.net/20170104214009596?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2h1c2xlaQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)

- 连接请求，SYN 报文， `SYN=1`,`seq=client_isn`
- 授予连接，ACK 报文， `SYN=1`,`seq=server_isn`,`ack=client_isn+1`
- 确认，ACK 报文， `SYN=0`,`seq=client_isn+1`,`ack=server_isn+1`

#### 为什么不是两次？

无法确认客户端的接收能力。主要防止已经失效的连接请求报文【网络堵塞】突然又传送到了服务器，从而产生错误。

#### TCP 三次握手中，最后一次回复丢失，会发生什么？

如果最后一次 ACK 在网络中丢失，那么 Server 端（服务端）该 TCP 连接的状态仍为 SYN_RECV，并且根据 TCP 的超时重传机制依次等待 3 秒、6 秒、12 秒后重新发送 SYN+ACK 包，以便 Client（客户端）重新发送 ACK 包。如果重发指定次数后，仍然未收到 ACK 应答，那么一段时间后，Server（服务端）自动关闭这个连接，但是 Client（客户端）认为这个连接已经建立，如果 Client（客户端）端向 Server（服务端）发送数据，Server 端（服务端）将以 RST 包（Reset，标示复位，用于异常的关闭连接）响应，此时，客户端知道第三次握手失败。

#### 什么是 SYN 洪泛攻击(SYN Flood，半开放攻击)？

SYN Flood 利用 TCP 协议缺陷，发送大量伪造的 TCP 连接请求，常用假冒的 IP 或 IP 号段发来海量的【请求连接的第一个握手包（SYN 包）】，被攻击服务器回应第二个握手包（SYN+ACK 包），因为对方是假冒 IP，对方永远收不到包且不会回应第三个握手包。导致被攻击服务器保持大量 SYN_RECV 状态的“半连接”，并且会重试默认 5 次回应第二个握手包，大量随机的恶意 syn 占满了未完成连接队列，导致正常合法的 syn 排不上队列，让正常的业务请求连接不进来。【服务器端的资源分配是在二次握手时分配的，而客户端的资源是在完成三次握手时分配的，所以服务器容易受到 SYN 洪泛攻击】

检测 SYN 攻击非常的方便，当你在服务器上看到大量的半连接状态时，特别是源 IP 地址是随机的，基本上可以断定这是一次 SYN 攻击【在 Linux/Unix 上可以使用系统自带的 netstats 命令来检测 SYN 攻击】

怎么解决？

- 缩短超时（SYN Timeout）时间
- 增加最大半连接数
- 过滤网关防护
- SYN cookies 技术
  - 当服务器接受到 SYN 报文段时，不直接为该 TCP 分配资源，而只是打开一个半开的套接字。接着会使用 SYN 报文段的源 Id，目的 Id，端口号以及只有服务器自己知道的一个秘密函数生成一个 cookie，并把 cookie 作为序列号响应给客户端。
  - 如果客户端是正常建立连接，将会返回一个确认字段为 cookie + 1 的报文段。接下来服务器会根据确认报文的源 Id，目的 Id，端口号以及秘密函数计算出一个结果，如果结果的值 + 1 等于确认字段的值，则证明是刚刚请求连接的客户端，这时候才为该 TCP 分配资源

#### 四次挥手，断开连接

> 标准动作：发送报文，响应报文，随机数+1，状态改变

- 一开始都处于 ESTABLISHED 状态，然后客户端发送 FIN 报文，带上 seq = p，状态变为 FIN-WAIT-1
- 服务端收到之后，发送 ACK 确认，ack = p + 1，然后进入 CLOSE-WAIT 状态，客户端收到之后进入 FIN-WAIT-2 状态
- 过了一会等数据处理完，服务端再次发送 FIN、ACK，seq = q，ack = p + 1，进入 LAST-ACK 阶段
- 客户端收到 FIN 之后，发送 ACK 给服务端 ack = q + 1，客户端收到之后进入 TIME_WAIT（等待 2MSL）
- 服务端收到之后进入 CLOSED 状态

- FIN,seq=client_isn
- ACK,ack=client_isn+1
- FIN,seq=server_isn,ack=client_isn+1
- ACK,ack=server_isn+1

![三次握手四次挥手](http://hi.csdn.net/attachment/201108/7/0_131271823564Rx.gif)

![Client状态变更过程](http://hi.csdn.net/attachment/201108/7/0_1312719804oSkK.gif)

![Server状态变更过程](http://hi.csdn.net/attachment/201108/7/0_1312719833030b.gif)

#### 为什么需要等待 2MSL（Maximum Segement Lifetime）：

如果服务端还有很多数据包要给客户端发，且此时客户端端口被新应用占据，那么客户端不等待的话，就会接收到无用的数据包，造成数据包混乱，所以说保险起见，就是等服务器发来的数据包都超时失效（死翘翘了）后再启动新应用。

1 个 MSL 保证四次挥手中主动关闭方最后的 ACK 报文能最终到达对端；
1 个 MSL 保证对端没有收到 ACK 那么进行重传的 FIN 报文能够到达；

#### 为什么是四次而非三次？

建立连接时，当 Server 端收到 Client 端的 SYN 连接请求报文后，可以直接发送 SYN+ACK 报文，相当于握手次数二合一；关闭连接时，当 Server 端收到 FIN 报文时，很可能并不会立即关闭 SOCKET，握手次数不能合二为一。

如果都是三次的话，那么服务端的 ACK 和 FIN 合并成一个挥手，那么长时间的延迟可能让 TCP 一位 FIN 没有达到服务器端，然后让客户的不断的重发 FIN

#### ISN 代表什么？意义何在？ISN 是固定不变的吗？ISN 为何要动态随机？

- ISN，发送方的字节数据编号的原点，让对方生成一个合法的接收窗口。
- ISN 是动态随机。为了增加安全性，避免被第三方猜测到，从而被第三方伪造的 RST 报文 Reset。
- ISN 动态随机使得每个 tcp session 的字节序列号没有重叠，如果出现 tcp 五元组冲突这种极小概率的情况，一个 session 的数据也不会被误认为是另一个 session 的。

#### 刚才你提到第三方可以伪造 RST 报文，需要满足什么条件才能得逞？

需要 sequence number 位于对方的合法接收窗口内。 而由于 ISN 是动态随机的，猜出对方合法接收窗口难度加大。如果 ISN = 0，那么猜出的难度就大大降低。

#### 三次握手的第一次可以携带数据吗？为何？

不可以，三次握手还没有完成。

#### 对方难道不可以将数据缓存下来，等握手成功再提交给应用程序？

这样会放大 SYN FLOOD 攻击。如果攻击者伪造了成千上万的握手报文，携带了 1K+ 字节的数据，而接收方会开辟大量的缓存来容纳这些巨大数据，内存会很容易耗尽，从而拒绝服务。

#### 第三次可以携带数据吗？为何？

可以。

#### 能够发出第三次握手报文的主机，肯定接收到第二次(服务器)握手报文，对吗？

因为伪造 IP 的主机是不会接收到第二次报文的。所以，能够发出第三次握手报文的，应该是合法的用户。尽管服务器侧的状态还没有“established”，接收到第三次握手的瞬间，状态就会切换为“established”，里面携带的数据按照正常流程走就好。

#### 看到有人说，只看到过 TCP 状态位为 ’FIN +ACK’，但从来没有看过状态位只有 ‘FIN’，你应该怎样给他解释？

RFC793 明确规定，除了第一个握手报文 SYN 除外，其它所有报文必须将 ACK = 1。

#### 很好，RFC 规定的背后肯定有合理性的一面，能否深究一下原因？

TCP 作为一个可靠传输协议，其可靠性就是依赖于收到对方的数据，ACK 对方，这样对方就可以释放缓存的数据，因为对方确信数据已经被接收到了。但 TCP 报文是在 IP 网络上传输，丢包是家常便饭，接收方要抓住一切的机会，把消息告诉发送方。最方便的方式就是，任何我方发送的 TCP 报文，都要捎带着 ACK 状态位。

#### ACK 状态位单独能承担这个消息传递的任务吗？

不能！需要有 Acknowledge Number 配合才行。如果我方发出的 Acknowledge Number == 10001，那意味着序列号 10000 及之前的字节已经成功接收。如果对方占据字节序列号 10000 是应用层数据，那么就是确认应用层数据。如果对方占据字节序列号 10000 是’FIN’状态位，那么就是确认接收到对方的’FIN’。

### 在交互过程中如果数据传送完了，还不想断开连接怎么办，怎么维持？

在 HTTP 中响应体的 Connection 字段指定为 keep-alive

### [你对 TCP 滑动窗口有了解嘛？](https://juejin.im/post/5e527c58e51d4526c654bf41#heading-38)

【流量控制】，在 TCP 链接中，对于发送端和接收端而言，TCP 需要把发送的数据放到发送缓存区，将接收的数据放到接收缓存区。而经常会存在发送端发送过多，而接收端无法消化的情况，所以就需要流量控制，就是通过接收缓存区的大小，控制发送端的发送。如果对方的接收缓存区满了，就不能再继续发送了。而这种流量控制的过程就需要在发送端维护一个发送窗口，在接收端维持一个接收窗口。

TCP 滑动窗口分为两种: 发送窗口和接收窗口。

### WebSocket 与 Ajax 的区别

#### 本质不同

- Ajax 即异步 JavaScript 和 XML，是一种创建交互式网页应用的网页开发技术
- websocket 是 HTML5 的一种新协议，实现了浏览器和服务器的实时通信

#### 生命周期不同

- ajax 发送接收之后就会断开
- websocket 是长连接，会话一直保持

#### 适用范围

- ajax 非实时
- websocket 用于前后端实时交互数据

#### 发起人

- AJAX 客户端发起
- WebSocket 服务器端和客户端相互推送

### 了解 WebSocket 嘛？

长轮询和短轮询，WebSocket 是长轮询。

具体比如在一个电商场景，商品的库存可能会变化，所以需要及时反映给用户，所以客户端会不停的发请求，然后服务器端会不停的去查变化，不管变不变，都返回，这个是短轮询。

而长轮询则表现为如果没有变，就不返回，而是等待变或者超时（一般是十几秒）才返回，如果没有返回，客户端也不需要一直发请求，所以减少了双方的压力。

### [HTTP 如何实现长连接？在什么时候会超时？](https://www.jianshu.com/p/3fc3646fad80)

通过在头部（请求和响应头）设置 Connection: keep-alive，HTTP1.0 协议支持，但是默认关闭，从 HTTP1.1 协议以后，连接默认都是长连接

HTTP 一般会有 httpd 守护进程，里面可以设置 keep-alive timeout，当 tcp 连接闲置超过这个时间就会关闭，也可以在 HTTP 的 header 里面设置超时时间

TCP 的 keep-alive 包含三个参数，支持在系统内核的 net.ipv4 里面设置：当 TCP 连接之后，闲置了 tcp_keepalive_time，则会发生侦测包，如果没有收到对方的 ACK，那么会每隔 tcp_keepalive_intvl 再发一次，直到发送了 tcp_keepalive_probes，就会丢弃该连接。

- tcp_keepalive_intvl = 15
- tcp_keepalive_probes = 5
- tcp_keepalive_time = 1800

实际上 HTTP 没有长短链接，只有 TCP 有，TCP 长连接可以复用一个 TCP 连接来发起多次 HTTP 请求，这样可以减少资源消耗，比如一次请求 HTML，可能还需要请求后续的 JS/CSS/图片等

### [Fetch API 与传统 Request 的区别](https://github.com/camsong/blog/issues/2)

- fetch 符合关注点分离，使用 Promise，API 更加丰富，支持 Async/Await
- 语意简单，更加语意化
- 可以使用 isomorphic-fetch ，同构方便

### POST 一般可以发送什么类型的文件，数据处理的问题

- 文本、图片、视频、音频等都可以
- text/image/audio/ 或 application/json 等

### OPTION 是干啥的？举个用到 OPTION 的例子？

旨在发送一种探测请求，以确定针对某个目标地址的请求必须具有怎么样的约束，然后根据约束发送真正的请求。【预检请求】

比如针对跨域资源的预检，就是采用 HTTP 的 OPTIONS 方法先发送的。用来处理跨域请求

### TCP 如何保证有效传输及拥塞控制原理

- tcp 是面向连接的、可靠的、传输层通信协议
  - 可靠体现在：有状态、可控制
- 有状态是指 TCP 会确认发送了哪些报文，接收方受到了哪些报文，哪些没有收到，保证数据包按序到达，不允许有差错
- 可控制的是指，如果出现丢包或者网络状况不佳，则会跳转自己的行为，减少发送的速度或者重发

所以上面能保证数据包的有效传输。

#### 拥塞控制原理

原因是有可能整个网络环境特别差，容易丢包，那么发送端就应该注意了。

主要用三种方法：

- 慢启动阈值 + 拥塞避免
- 快速重传
- 快速回复

#### 慢启动阈值 + 拥塞避免

对于拥塞控制来说，TCP 主要维护两个核心状态：

- 拥塞窗口（cwnd）
- 慢启动阈值（ssthresh）

> 在发送端使用拥塞窗口来控制发送窗口的大小。

然后采用一种比较保守的慢启动算法来慢慢适应这个网络，在开始传输的一段时间，发送端和接收端会首先通过三次握手建立连接，确定各自接收窗口大小，然后初始化双方的拥塞窗口，接着每经过一轮 RTT（收发时延），拥塞窗口大小翻倍，直到达到慢启动阈值。

然后开始进行拥塞避免，拥塞避免具体的做法就是之前每一轮 RTT，拥塞窗口翻倍，现在每一轮就加一个。

#### 快速重传

在 TCP 传输过程中，如果发生了丢包，接收端就会发送之前重复 ACK，比如 第 5 个包丢了，6、7 达到，然后接收端会为 5，6，7 都发送第四个包的 ACK，这个时候发送端受到了 3 个重复的 ACK，意识到丢包了，就会马上进行重传，而不用等到 RTO （超时重传的时间）

选择性重传：报文首部可选性中加入 SACK 属性，通过 left edge 和 right edge 标志那些包到了，然后重传没到的包

#### 快速恢复

如果发送端收到了 3 个重复的 ACK，发现了丢包，觉得现在的网络状况已经进入拥塞状态了，那么就会进入快速恢复阶段：

- 会将拥塞阈值降低为 拥塞窗口的一半
- 然后拥塞窗口大小变为拥塞阈值
- 接着 拥塞窗口再进行线性增加，以适应网络状况
